{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **1. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [],
      "source": [
        "# 1. Memuat Dataset\n",
        "data = pd.read_csv('clustered_data.csv')\n",
        "print(\"Dataset Head:\")\n",
        "print(data.head())\n",
        "\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPem5eWL2UP"
      },
      "source": [
        "# **3. Data Splitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      },
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "outputs": [],
      "source": [
        "# 2. Data Splitting\n",
        "X = data.drop(columns=['CustomerOccupation'])\n",
        "y = data['CustomerOccupation']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=None)\n",
        "\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
        "X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVPbB03CMhTT"
      },
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ned1pL9zMmBK"
      },
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAWzPOE4Nkti"
      },
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=500),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "tuned_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    param_grid = {}\n",
        "    if name == 'Logistic Regression':\n",
        "        param_grid = {'C': [0.01, 0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']}\n",
        "    elif name == 'Random Forest':\n",
        "        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
        "    \n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train[numeric_columns], y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    tuned_models[name] = best_model\n",
        "    \n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(max_iter=500),\n",
        "        'Random Forest': RandomForestClassifier()\n",
        "    }\n",
        "\n",
        "    tuned_models = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        param_grid = {}\n",
        "        if name == 'Logistic Regression':\n",
        "            param_grid = {'C': [0.01, 0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']}\n",
        "        elif name == 'Random Forest':\n",
        "            param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
        "        \n",
        "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "        grid_search.fit(X_train[numeric_columns], y_train)\n",
        "        best_model = grid_search.best_estimator_\n",
        "        tuned_models[name] = best_model\n",
        "        \n",
        "        y_pred = best_model.predict(X_test[numeric_columns])\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        \n",
        "        print(f\"\\n{name} - Best Parameters: {grid_search.best_params_}\")\n",
        "        print(f\"{name} Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    \n",
        "    print(f\"\\n{name} - Best Parameters: {grid_search.best_params_}\")\n",
        "    print(f\"{name} Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seYoHNY3XU1y"
      },
      "source": [
        "- Model yang digunakan adalan **Random Forest Classifier** dengan 100 pohon keputusan.\n",
        "- Model ini akan belajar dari data latih untuk mengenali pola transaksi berdasarkan cluster yang sudah ditentukan sebelumnya.\n",
        "- Setelah model dilatih, kita bisa menggunakannya untuk melakukan prediksi pada data uji dan mengevaluasi kinerjanya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ergzChZFEL-O"
      },
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOm68u-7NpLT"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(f'Confusion Matrix - {name}')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4_9OwrsXZlz"
      },
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph9yIYDXEPuB"
      },
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bikx3LINv5e"
      },
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "outputs": [],
      "source": [
        "# 5c. Tuning Model dengan GridSearchCV (Optional)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "rf = RandomForestClassifier()\n",
        "gs = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "gs.fit(X_train[numeric_columns], y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE7pqlEPEYzI"
      },
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feaPESoeN0zz"
      },
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTXZRvEeNMb1"
      },
      "outputs": [],
      "source": [
        "# Evaluasi Model Setelah Tuning\n",
        "y_pred_best = best_model.predict(X_test[numeric_columns])\n",
        "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
        "f1_best = f1_score(y_test, y_pred_best, average='weighted')\n",
        "\n",
        "print(\"Evaluasi Model Setelah Tuning:\")\n",
        "print(f\"Accuracy: {accuracy_best:.4f}\")\n",
        "print(f\"F1-Score: {f1_best:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_best))\n",
        "\n",
        "# Perbandingan hasil sebelum dan sesudah tuning\n",
        "improvement = accuracy_best - acc\n",
        "print(f\"Peningkatan Akurasi setelah tuning: {improvement:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      },
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5b. Evaluasi Model Klasifikasi\n",
        "eval_results = {}\n",
        "for name, model in tuned_models.items():\n",
        "    y_pred = model.predict(X_test[numeric_columns])\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    eval_results[name] = {'Accuracy': acc, 'F1-Score': f1}\n",
        "    print(f\"\\nEvaluasi {name}:\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
